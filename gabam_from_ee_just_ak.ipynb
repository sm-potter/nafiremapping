{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d45a4059-008e-4975-87b1-4e550a2c9ece",
   "metadata": {},
   "source": [
    "This script will get the omission, comission and intersection numbers from GABAM and MTBS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae64899-e491-4049-bedc-a877a91fc497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import numpy as np\n",
    "from geeml.extract import extractor\n",
    "import pandas as pd\n",
    "import geemap\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from google.cloud import client\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\"\n",
    "\n",
    "service_account = 'gee-serdp-upload@appspot.gserviceaccount.com'\n",
    "credentials = ee.ServiceAccountCredentials(service_account, \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\")\n",
    "ee.Initialize(credentials)\n",
    "\n",
    "ee.Initialize()\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"gee-serdp-upload\"\n",
    "storage_client = storage.Client()\n",
    "# bucket_name = 'smp-scratch/mtbs_1985'\n",
    "bucket_name = 'smp-scratch'\n",
    "\n",
    "bucket = storage_client.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4142a0c-b4fc-4446-b8f6-e398b1b3604a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#for water masking\u001b[39;00m\n\u001b[1;32m     10\u001b[0m water \u001b[38;5;241m=\u001b[39m ee\u001b[38;5;241m.\u001b[39mImageCollection(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJRC/GSW1_4/YearlyHistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m water \u001b[38;5;241m=\u001b[39m water\u001b[38;5;241m.\u001b[39mfilterDate(\u001b[38;5;28mstr\u001b[39m(year) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(year) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-12-31\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwaterClass\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mclip(\u001b[43mgrd\u001b[49m\u001b[38;5;241m.\u001b[39munion())\n\u001b[1;32m     12\u001b[0m water \u001b[38;5;241m=\u001b[39m water\u001b[38;5;241m.\u001b[39mupdateMask(water\u001b[38;5;241m.\u001b[39meq(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#grid used for predicting on and we will loop through to save memory\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grd' is not defined"
     ]
    }
   ],
   "source": [
    "#year of interest\n",
    "years = [2004, 2005, 2009, 2010, 2013, 2015]\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    #buffered fire polygons\n",
    "    buffer = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/2001_2023_buff\").filter(ee.Filter.eq('Year',  year))   \n",
    "    \n",
    "    #grid used for predicting on and we will loop through to save memory\n",
    "    grd = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ak_grid_20000\")\n",
    "    \n",
    "    #for water masking\n",
    "    water = ee.ImageCollection(\"JRC/GSW1_4/YearlyHistory\")\n",
    "    water = water.filterDate(str(year) + '-01-01', str(year) + '-12-31').max().select('waterClass').clip(grd.union())\n",
    "    water = water.updateMask(water.eq(3))\n",
    "\n",
    "    #modis land cover for now, we will switch this eventually\n",
    "    lc = ee.ImageCollection(\"MODIS/061/MCD12Q1\")\n",
    "\n",
    "    #read in gabam which is a 30m random forest model\n",
    "    gabam = ee.ImageCollection(\"projects/sat-io/open-datasets/GABAM\")\n",
    "\n",
    "    gabam = gabam.filterDate(str(year) + '-01-01', str(year) + '-12-31').mean()\n",
    "\n",
    "    #clip lc\n",
    "    lc = lc.filterDate(str(year) + '-01-01', str(year) + '-12-31').max().clip(grd.union())\n",
    "    lc = lc.select('LC_Type1')\n",
    "\n",
    "    #union to a single feature for the grd\n",
    "    aoi = grd.union()\n",
    "\n",
    "    \n",
    "    #get modis active fire and merge with viirs\n",
    "    Terra_Fire = ee.ImageCollection(\"MODIS/061/MOD14A1\").filterBounds(aoi)\n",
    "    Aqua_Fire = ee.ImageCollection(\"MODIS/061/MYD14A1\").filterBounds(aoi)\n",
    "\n",
    "    #merge and filter modis\n",
    "    mod_fire = Terra_Fire.merge(Aqua_Fire).filterBounds(aoi).filterDate(str(year) + '-01-01', str(year) + '-12-31')\n",
    "    \n",
    "    #add day of year as band\n",
    "    def add_bands(image):\n",
    "        image = image.addBands(ee.Image(ee.Date(image.get('system:time_start')).getRelative('day','year').add(1)).clamp(1,366)).updateMask(image.select('FireMask').gte(7))\n",
    "        return image.updateMask(image.select('constant').gt(60))\n",
    "\n",
    "\n",
    "    mod_fire =  mod_fire.map(add_bands)\n",
    "\n",
    "    mod_fire = mod_fire.select('constant').max().clip(aoi)\n",
    "\n",
    "\n",
    "    #now buffer the buffered fire polygons, turn it to an image and merge with modis and viirs\n",
    "    def to_year(f):\n",
    "        return f.set({'Year': year})\n",
    "\n",
    "\n",
    "    buffer = buffer.map(to_year)\n",
    "\n",
    "    #turn vector to image\n",
    "    buff_img = buffer.reduceToImage(\n",
    "      properties= ['Year'],\n",
    "      reducer= ee.Reducer.max()).clip(aoi).select(['max'], ['constant'])\n",
    "\n",
    "    #merge modis and mtbs\n",
    "    mod_mtbs = ee.ImageCollection([buff_img, mod_fire]).max()\n",
    "\n",
    "    #only merge with viirs if the year is >= 2012, otherwise it does not exist\n",
    "    if year >= 2012:\n",
    "\n",
    "        #read in viirs\n",
    "        viirs = ee.Image(\"users/spotter/fire_cnn/VIIRS/\" + str(year))\n",
    "        viirs = viirs.clip(aoi).select(['b1'], ['constant'])\n",
    "\n",
    "        #merge all\n",
    "        final = ee.ImageCollection([viirs, mod_mtbs]).max().updateMask(lc.neq(12).And(lc.neq(16)))\n",
    "\n",
    "    else:\n",
    "\n",
    "        final = mod_mtbs\n",
    "\n",
    "    # read in the predictions and mask them with the areas\n",
    "    predictions = ee.ImageCollection('projects/gee-serdp-upload/assets/cnn_mapping/mtbs_' + str(year) + '_preds_128_32').max().clip(aoi)\n",
    "\n",
    "    #threshold at 0.5 probability\n",
    "    thresholded = predictions.select('prediction').updateMask(final).updateMask(predictions.select('prediction').gte(0.5))\n",
    "\n",
    "    #water mask\n",
    "    thresholded = thresholded.updateMask(water.unmask().Not())\n",
    "\n",
    "    #remove areas from gabam where I didn't have imagery\n",
    "    gabam = gabam.updateMask(predictions)\n",
    "\n",
    "\n",
    "    gabam = gabam.updateMask(lc.neq(12).And(lc.neq(16)))\n",
    "\n",
    "\n",
    "    #large fire databases which is mtbs and nbac\n",
    "    lfdb = ee.FeatureCollection('users/spotter/fire_cnn/raw/ak_ca_1985')\n",
    "\n",
    "    lfdb = lfdb.filter(ee.Filter.eq(\"Year\", year))\n",
    "\n",
    "\n",
    "    #make image of fire databases\n",
    "    lfdb_img = lfdb.reduceToImage(\n",
    "      properties= ['Year'],\n",
    "      reducer= ee.Reducer.max()).clip(aoi).select(['max'], ['constant'])\n",
    "    \n",
    "    #we will also want the area of ALFD as well though so do the same thing for it\n",
    "    alfd = ee.FeatureCollection('users/spotter/fire_cnn/raw/ak_lfdb_1985')\n",
    "\n",
    "    alfd = alfd.filter(ee.Filter.eq(\"Year\", year))\n",
    "\n",
    "\n",
    "    #make image of fire databases\n",
    "    alfd_img = alfd.reduceToImage(\n",
    "      properties= ['Year'],\n",
    "      reducer= ee.Reducer.max()).clip(aoi).select(['max'], ['constant'])\n",
    "    \n",
    "\n",
    "    #water mask to our predictions\n",
    "    thresholded = thresholded.updateMask(water.unmask().Not())\n",
    "    \n",
    "    \n",
    "\n",
    "    #get intersection of us and mtbs\n",
    "    us_int = lfdb_img.updateMask(predictions.gte(0.5)).select(['constant'], ['us_int'])\n",
    "\n",
    "    #get omission of us and mtbs (mtbs has fire we do not)\n",
    "    us_om = lfdb_img.updateMask(thresholded.unmask().Not()).select(['constant'], ['us_om'])\n",
    "\n",
    "    #get comission of us and mtbs  (we have fire but mtbs does not)\n",
    "    us_com = thresholded.updateMask(lfdb_img.unmask().Not()).select(['prediction'], ['us_com'])\n",
    "\n",
    "    #get intersection of gabam and mtbs\n",
    "    gabam_int = lfdb_img.updateMask(gabam).select(['constant'], ['gabam_int'])\n",
    "\n",
    "    #get omission of gabam and mtbs\n",
    "    gabam_om = lfdb_img.updateMask(gabam.unmask().Not()).select(['constant'], ['gabam_om'])\n",
    "\n",
    "    #get comission of gabam and mtbs\n",
    "    gabam_com = gabam.updateMask(lfdb_img.unmask().Not()).select(['b1'], ['gabam_com'])\n",
    "\n",
    "    \n",
    "    #all grid cells to loop through for area calculations\n",
    "    all_territories = ee.List(grd.distinct([\"Id\"]).aggregate_array(\"Id\")).getInfo()\n",
    "\n",
    "    for this_id in all_territories:\n",
    "        \n",
    "        #full pathway to images within the collection\n",
    "        fname = 'om_com_' + str(year) + '_' + str(this_id)\n",
    "        \n",
    "        #check if output exists\n",
    "        bucket_name = 'smp-scratch'\n",
    "        storage_client = storage.Client()\n",
    "\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "        stats = storage.Blob(bucket=bucket, name=fname).exists(storage_client)\n",
    "        \n",
    "        if stats == False:\n",
    "            \n",
    "            #filter sub grid cell of interest\n",
    "            sub_id = grd.filter(ee.Filter.eq('Id',  this_id))\n",
    "\n",
    "            #now get areas and convert to feature collection and send out to csv\n",
    "            #now get the areas\n",
    "            pa = ee.Image.pixelArea()\n",
    "\n",
    "            #areas are in m2\n",
    "            \n",
    "            #this is mtbs\n",
    "            img_area = pa.updateMask(lfdb_img).reduceRegion(\n",
    "                reducer= ee.Reducer.sum(),\n",
    "                geometry= sub_id,\n",
    "                scale= 30,\n",
    "                tileScale= 16,\n",
    "                crs= 'EPSG:3413',\n",
    "                # maxPixels= 1e9,\n",
    "                bestEffort=False,\n",
    "                maxPixels= 1e13\n",
    "            ).get('area')\n",
    "            \n",
    "            #alfd\n",
    "            alfd_area = pa.updateMask(alfd_img).reduceRegion(\n",
    "                reducer= ee.Reducer.sum(),\n",
    "                geometry= sub_id,\n",
    "                scale= 30,\n",
    "                tileScale= 16,\n",
    "                crs= 'EPSG:3413',\n",
    "                # maxPixels= 1e9,\n",
    "                bestEffort=False,\n",
    "                maxPixels= 1e13\n",
    "            ).get('area')\n",
    "\n",
    "            us_int_area = pa.updateMask(us_int).reduceRegion(\n",
    "                reducer= ee.Reducer.sum(),\n",
    "                geometry= sub_id,\n",
    "                scale= 30,\n",
    "                tileScale= 16,\n",
    "                crs= 'EPSG:3413',\n",
    "                # maxPixels= 1e9,\n",
    "                bestEffort=False,\n",
    "                maxPixels= 1e13\n",
    "            ).get('area')\n",
    "\n",
    "            us_om_area = pa.updateMask(us_om).reduceRegion(\n",
    "                reducer= ee.Reducer.sum(),\n",
    "                geometry= sub_id,\n",
    "                scale= 30,\n",
    "                tileScale= 16,\n",
    "                crs= 'EPSG:3413',\n",
    "                # maxPixels= 1e9,\n",
    "                bestEffort=False,\n",
    "                maxPixels= 1e13\n",
    "              ).get('area')\n",
    "\n",
    "            us_com_area = pa.updateMask(us_com).reduceRegion(\n",
    "                reducer= ee.Reducer.sum(),\n",
    "                geometry= sub_id,\n",
    "                scale= 30,\n",
    "                tileScale= 16,\n",
    "                crs= 'EPSG:3413',\n",
    "                # maxPixels= 1e9,\n",
    "                bestEffort=False,\n",
    "                maxPixels= 1e13\n",
    "            ).get('area')\n",
    "\n",
    "            gabam_int_area = pa.updateMask(gabam_int).reduceRegion(\n",
    "                reducer= ee.Reducer.sum(),\n",
    "                geometry= sub_id,\n",
    "                scale= 30,\n",
    "                tileScale= 16,\n",
    "                crs= 'EPSG:3413',\n",
    "                # maxPixels= 1e9,\n",
    "                bestEffort=False,\n",
    "                maxPixels= 1e13\n",
    "            ).get('area')\n",
    "\n",
    "            gabam_om_area = pa.updateMask(gabam_om).reduceRegion(\n",
    "                reducer= ee.Reducer.sum(),\n",
    "                geometry= sub_id,\n",
    "                scale= 30,\n",
    "                tileScale= 16,\n",
    "                crs = 'EPSG:3413',\n",
    "                # maxPixels= 1e9,\n",
    "                bestEffort=False,\n",
    "                maxPixels= 1e13\n",
    "              ).get('area')\n",
    "\n",
    "            gabam_com_area = pa.updateMask(gabam_com).reduceRegion(\n",
    "                reducer= ee.Reducer.sum(),\n",
    "                geometry= sub_id,\n",
    "                scale= 30,\n",
    "                tileScale= 16,\n",
    "                crs= 'EPSG:3413',\n",
    "                # maxPixels= 1e9,\n",
    "                bestEffort=False,\n",
    "                maxPixels= 1e13\n",
    "            ).get('area')\n",
    "\n",
    "            \n",
    "            #get a feature for each cire area with appropriate attributes\n",
    "            us_int_feat = ee.Feature(None, {'Year': year, 'ID': this_id, 'Class': 'Us_Int', 'Area': us_int_area})\n",
    "            us_om_feat = ee.Feature(None, {'Year': year, 'ID': this_id, 'Class': 'Us_Om', 'Area': us_om_area})\n",
    "            us_com_feat = ee.Feature(None, {'Year': year, 'ID': this_id, 'Class': 'Us_Com', 'Area': us_com_area})\n",
    "            gabam_int_feat = ee.Feature(None, {'Year': year, 'ID': this_id, 'Class': 'Gabam_Int', 'Area': gabam_int_area})\n",
    "            gabam_om_feat = ee.Feature(None, {'Year': year, 'ID': this_id, 'Class': 'Gabam_Om', 'Area': gabam_om_area})\n",
    "            gabam_com_feat = ee.Feature(None, {'Year': year, 'ID': this_id, 'Class': 'Gabam_Com', 'Area': gabam_com_area})\n",
    "            mtbs_feat = ee.Feature(None, {'Year': year, 'ID': this_id, 'Class': 'MTBS_Area', 'Area': img_area})\n",
    "            alfd_feat = ee.Feature(None, {'Year': year, 'ID': this_id, 'Class': 'ALFD_Area', 'Area': img_area})\n",
    "\n",
    "                \n",
    "            #combine to feature collection\n",
    "            final_sub = ee.FeatureCollection([us_int_feat, us_om_feat, us_com_feat, gabam_int_feat, gabam_om_feat, gabam_com_feat, mtbs_feat, alfd_feat])\n",
    "            \n",
    "            #download\n",
    "            print('Downloading ' +  'om_com_' + str(year) + '_' + str(this_id))\n",
    "            \n",
    "            task = ee.batch.Export.table.toCloudStorage(collection = final_sub, \n",
    "                                        description = fname,\n",
    "                                        bucket =  'smp-scratch', \n",
    "                                        fileFormat = 'CSV')\n",
    "\n",
    "            task.start()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-gee_ml]",
   "language": "python",
   "name": "conda-env-.conda-gee_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
