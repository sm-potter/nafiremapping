{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ce429d-af33-40fd-8638-e62ffa201576",
   "metadata": {},
   "source": [
    "Read in all the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5183878f-0f72-42ec-84f0-8fda2b884ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import geemap\n",
    "from geeml.extract import extractor\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\"\n",
    "\n",
    "service_account = 'gee-serdp-upload@appspot.gserviceaccount.com'\n",
    "credentials = ee.ServiceAccountCredentials(service_account, \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\")\n",
    "# ee.Authenticate()\n",
    "ee.Initialize(credentials)#h high-volume end-point\n",
    "ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "# ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6339b2d9-156a-4faf-9c54-c44ee0386686",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4fed490-e4cc-4181-8c0e-4628163b00b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import geemap\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from google.cloud import client\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7079fbd-131b-4590-a7c0-95b1b658bc75",
   "metadata": {},
   "source": [
    "Read in assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "112d5a6a-b286-4cc1-8e72-242e93a52be8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11253\n"
     ]
    }
   ],
   "source": [
    "dem = ee.Image(\"UMN/PGC/ArcticDEM/V3/2m_mosaic\") #arctic dem\n",
    "sent_2A = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "ak = ee.FeatureCollection(\"users/spotter/alaska\") #ak shapefile\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ak_lfdb_1985\") #ak fire polygons\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ak_lfdb_2014\") #ak fire polygons\n",
    "lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/nbac_1985\") #ak fire polygons\n",
    "\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/nbac_2013\") #ak fire polygons\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ak_mtbs_2014\")\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ak_mtbs_1985\")\n",
    "\n",
    "water = ee.ImageCollection(\"JRC/GSW1_3/YearlyHistory\") #water mask\n",
    "# lfdb = lfdb.filter(ee.Filter.gte('Year', 2014))\n",
    "print(lfdb.size().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c71066-127f-4646-b689-b4a3f4cd7fb3",
   "metadata": {},
   "source": [
    "Mask snow and clouds Landsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce92ff2f-51bc-4ee6-b766-717dccd40367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#remove clouds from sentinel 2, cloud probability of less than 15%\n",
    "def sent_maskcloud(image):\n",
    "\n",
    "  QA60 = image.select(['QA60'])\n",
    "  clouds = QA60.bitwiseAnd(1<<10).Or(QA60.bitwiseAnd(1<<11))# this gives us cloudy pixels\n",
    "  image = image.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12'], ['B1', 'B2', 'B3', 'B4', 'B5', 'B7'])# rename bands\n",
    "  image =  image.updateMask(clouds.Not()) # remove the clouds from image\n",
    "  \n",
    "  #different resolutions so change to 30 seperately\n",
    "  image1 = image.select(['B1', 'B2', 'B3', 'B4'], ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4'])\n",
    "  image2 = image.select(['SR_B5', 'SR_B7'])\n",
    "\n",
    "  #reproject 30m\n",
    "  image1 = image1.reproject(\n",
    "  crs = image1.projection().crs(),\n",
    "  scale = 30)\n",
    "  \n",
    "  image2 = image2.reproject(\n",
    "  crs = image2.projection().crs(),\n",
    "  scale = 30)\n",
    "  \n",
    "  image = image1.addBands(image2)\n",
    "  \n",
    "  return image.toShort()\n",
    "\n",
    "Box = ak.geometry()\n",
    "\n",
    "#better function to mask clouds\n",
    "\n",
    "MAX_CLOUD_PROBABILITY = 50\n",
    "\n",
    "def sent_maskcloud(image):\n",
    "    \n",
    "    \n",
    "    image = image.select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12'], ['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7'])# rename bands\n",
    "  \n",
    "    image =  image.toShort()\n",
    "    \n",
    "    clouds = ee.Image(image.get('cloud_mask')).select('probability')\n",
    "    \n",
    "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
    "    \n",
    "    image = image.updateMask(isNotCloud)\n",
    "\n",
    "    #reproject 30m but remember b1, b2 and b3 are 10 and the rest are 20\n",
    "    image1 = image.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4'])\n",
    "    image2 = image.select(['SR_B5', 'SR_B7'])\n",
    "\n",
    "    \n",
    "    image1 = image1.reproject(\n",
    "    crs = image1.projection().crs(),\n",
    "    scale = 30)\n",
    "    \n",
    "    \n",
    "    image2 = image2.reproject(\n",
    "    crs = image2.projection().crs(),\n",
    "    scale = 30)\n",
    "    \n",
    "    image = image1.addBands(image2)\n",
    "    \n",
    "    return image \n",
    "\n",
    "#Join S2 SR with cloud probability dataset to add cloud mask.\n",
    "s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(\n",
    "    \n",
    "  primary=sent_2A,\n",
    "  secondary=s2Clouds,\n",
    "  condition=ee.Filter.equals(leftField='system:index', rightField='system:index'))\n",
    "\n",
    "sent_2A = ee.ImageCollection(s2SrWithCloudMask).map(sent_maskcloud)\n",
    "\n",
    "#print first image to test\n",
    "#pprint.pprint(sent_2A.first().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2e0b6-7cad-4592-971e-e2a3fb7e4ab1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']\n"
     ]
    }
   ],
   "source": [
    "print(sent_2A.first().bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c863fb50-782b-4b7a-b25a-94d3d51ca032",
   "metadata": {},
   "source": [
    "Landsat Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35acd43f-65a9-46cf-9200-ef3591158bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mask(image):\n",
    "    qa = image.select('QA_PIXEL')                                       \n",
    "    mask = qa.bitwiseAnd(8).eq(0).And(qa.bitwiseAnd(10).eq(0)).And(qa.bitwiseAnd(32).eq(0))  \n",
    "    return(image.updateMask(mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a24e56c-4874-4707-ae38-85d1997bb0fd",
   "metadata": {},
   "source": [
    "Functions to correct all the bands, dNBR, NDII and NDVI  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46e3b4-715f-4518-ae64-e6c60d08f37b",
   "metadata": {},
   "source": [
    "Correct the landsat scale factor and sentinel scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0d1682d-8ad7-409f-918c-0c5fe6a46cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def land_scale(image):\n",
    "\n",
    "    return(image.multiply(0.0000275).add(-0.2))\n",
    "\n",
    "def sent_scale(image):\n",
    "    return(image.multiply(0.0001))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926c4ebf-0107-43e7-b251-5ec6ebeb58f2",
   "metadata": {},
   "source": [
    "More efficient way to apply the corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4fc86e6-ea59-4ceb-9325-1133d5822a41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_326108/639313901.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  l5['band.or.si']=pd.Categorical(l5['band.or.si'],categories=bands)\n",
      "/tmp/ipykernel_326108/639313901.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  l5['band.or.si']=pd.Categorical(l5['band.or.si'],categories=bands)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "coeffs = pd.read_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/raw_files/boreal_xcal_regression_coefficients.csv\").fillna(0)\n",
    "\n",
    "#l5\n",
    "def landsat_correct(sat, bands):\n",
    "\n",
    "    \"\"\"argument 1 is which sattelite, LANDASAT_5 or LANDSAT_8\n",
    "    argument 2 is bands of interest.  Bands must be in same order as EE,\n",
    "    \n",
    "    regression is of form,\n",
    "    L7 = B0 + (B1 * L5/8) + (B2 * L^2) + (B3 * L^3)\n",
    "    \"\"\"\n",
    "\n",
    "    #bands of interest in order of interest\n",
    "    l5 = coeffs[(coeffs['satellite'] == sat) & (coeffs['band.or.si'] .isin (bands))] \n",
    "\n",
    "    #arrange the band or si column\n",
    "    l5['band.or.si']=pd.Categorical(l5['band.or.si'],categories=bands)\n",
    "    l5=l5.sort_values('band.or.si')\n",
    "\n",
    "    b0 = l5['B0'].values.tolist()\n",
    "    b1 = l5['B1'].values.tolist()\n",
    "    b2 = l5['B2'].values.tolist()\n",
    "    b3 = l5['B3'].values.tolist()\n",
    "\n",
    "    return (b0, b1, b2, b3)\n",
    "\n",
    "#get the corrections, each output is a list at one of the four locations\n",
    "l8_corr = landsat_correct(sat = 'LANDSAT_8', bands = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2', 'nbr', 'ndvi', 'ndii'])\n",
    "l5_corr = landsat_correct(sat = 'LANDSAT_5', bands = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2', 'nbr', 'ndvi', 'ndii'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd48466-4651-40db-9c08-3fccfa2d8f37",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'t'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793967d-7d8a-4816-b08a-e5802713a298",
   "metadata": {},
   "source": [
    "Now lets try to do it directly through google cloud platform, first authenticate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0cf79c3-321c-4b93-8e1e-d019ea137db8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\"\n",
    "storage_client = storage.Client.from_service_account_json(\"/explore/nobackup/people/spotter5/cnn_mapping/gee-serdp-upload-7cd81da3dc69.json\")\n",
    "\n",
    "os.environ[\"GCLOUD_PROJECT\"] = \"gee-serdp-upload\"\n",
    "storage_client = storage.Client()\n",
    "# bucket_name = 'smp-scratch/mtbs_1985'\n",
    "bucket_name = 'smp-scratch'\n",
    "\n",
    "bucket = storage_client.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b823b48d-3592-44ba-a643-a12f2c54326c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_float(image):\n",
    "\n",
    "    b1 = image.select('SR_B1').cast({'SR_B1':'float'}) #0\n",
    "    b2 = image.select('SR_B2').cast({'SR_B2':'float'}) #1\n",
    "    b3 = image.select('SR_B3').cast({'SR_B3':'float'}) #2\n",
    "    b4 = image.select('SR_B4').cast({'SR_B4':'float'}) #3\n",
    "    b5 = image.select('SR_B5').cast({'SR_B5':'float'}) #4\n",
    "    b6 = image.select('SR_B7').cast({'SR_B7':'float'}) #5\n",
    "\n",
    "    image = b1.addBands(b2).addBands(b3).addBands(b4).addBands(b5).addBands(b6)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e80a9-0974-4a2e-a6ad-24f0084560cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading median_2827.tif\n",
      "Downloading median_7938.tif\n",
      "Downloading median_7974.tif\n",
      "Downloading median_7945.tif\n",
      "Downloading median_8164.tif\n",
      "Downloading median_8207.tif\n",
      "Downloading median_10813.tif\n",
      "Downloading median_10896.tif\n",
      "Downloading median_11082.tif\n",
      "Downloading median_10828.tif\n",
      "Downloading median_10866.tif\n",
      "Downloading median_11045.tif\n",
      "Downloading median_11064.tif\n",
      "Downloading median_10818.tif\n",
      "Downloading median_10831.tif\n",
      "Downloading median_10836.tif\n",
      "Downloading median_10930.tif\n",
      "Downloading median_11098.tif\n",
      "Downloading median_10399.tif\n",
      "Downloading median_10125.tif\n",
      "Downloading median_10312.tif\n",
      "Downloading median_10234.tif\n",
      "Downloading median_6742.tif\n",
      "Downloading median_9009.tif\n",
      "Downloading median_9992.tif\n",
      "Downloading median_3265.tif\n",
      "Downloading median_4356.tif\n",
      "Downloading median_5162.tif\n",
      "Downloading median_5165.tif\n",
      "Downloading median_9470.tif\n",
      "Downloading median_9242.tif\n",
      "Downloading median_9261.tif\n",
      "Downloading median_9291.tif\n",
      "Downloading median_10026.tif\n",
      "Downloading median_488.tif\n",
      "Downloading median_1139.tif\n",
      "Downloading median_1240.tif\n",
      "Downloading median_1388.tif\n",
      "Downloading median_1292.tif\n",
      "Downloading median_1386.tif\n",
      "Downloading median_2065.tif\n",
      "Downloading median_2287.tif\n",
      "Downloading median_2478.tif\n",
      "Downloading median_3058.tif\n",
      "Downloading median_3059.tif\n",
      "Downloading median_3672.tif\n",
      "Downloading median_3655.tif\n",
      "Downloading median_4778.tif\n",
      "Downloading median_4759.tif\n",
      "Downloading median_4519.tif\n",
      "Downloading median_4645.tif\n",
      "Downloading median_5516.tif\n",
      "Downloading median_5856.tif\n",
      "Downloading median_5639.tif\n",
      "Downloading median_5705.tif\n",
      "Downloading median_5787.tif\n",
      "Downloading median_5822.tif\n",
      "Downloading median_6142.tif\n",
      "Downloading median_6877.tif\n",
      "Downloading median_6923.tif\n",
      "Downloading median_6964.tif\n",
      "Downloading median_6789.tif\n",
      "Downloading median_6822.tif\n"
     ]
    }
   ],
   "source": [
    "lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/nbac_1985\") #ak fire polygons\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ak_mtbs_2014\")\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ak_mtbs_1985\")\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/ak_lfdb_1985\")\n",
    "\n",
    "# lfdb = ee.FeatureCollection(\"users/spotter/fire_cnn/raw/nbac_2013\") #ak fire polygons\n",
    "\n",
    "water = ee.ImageCollection(\"JRC/GSW1_3/YearlyHistory\") #water mask\n",
    "# lfdb = lfdb.filter(ee.Filter.gte('Year', 2014))\n",
    "\n",
    "all_dates = ee.List(lfdb.distinct([\"ID\"]).aggregate_array(\"ID\"))\n",
    "all_dates = all_dates.getInfo()\n",
    "# all_dates = [2173, 2174]\n",
    "# all_dates = [1399]\n",
    "# all_dates = [2549]\n",
    "\n",
    "#get list of all the tasks running\n",
    "all_tasks = ee.data.listOperations()\n",
    "\n",
    "\n",
    "all_names = [i['metadata']['description'] for i in all_tasks]\n",
    "all_states = [i['metadata']['state'] for i in all_tasks]\n",
    "\n",
    "#make dictionary where the keys are names and values are states\n",
    "my_dict = dict(zip(all_names, all_states))\n",
    "\n",
    "\n",
    "# all_dates = [1877]\n",
    "for i in all_dates:\n",
    "\n",
    "      # print(id)\n",
    "      # if id not in [1909, 1066, 1716]:\n",
    "      # if id in [3823]:\n",
    "\n",
    "      # try:\n",
    "\n",
    "    # print(raw_bands.toFloat().getInfo())\n",
    "    fname = f\"median_{i}.tif\"\n",
    "\n",
    "#     storage_client = storage.Client()\n",
    "#     # bucket_name = 'smp-scratch/mtbs_1985'\n",
    "#     bucket_name = 'smp-scratch'\n",
    "\n",
    "#     bucket = storage_client.bucket(bucket_name)\n",
    "    stats = storage.Blob(bucket=bucket, name=fname).exists(storage_client)\n",
    "    if stats == False:\n",
    "        \n",
    "#         #get the name of interest\n",
    "#         this_item = my_dict[fname.replace('.tif', '')]\n",
    "        \n",
    "#         #make sure the item is not pending\n",
    "#         if this_item not in ['PENDING', 'SUCCEEDED']:\n",
    "          # if fname.replace('.tif', '') not in my_dict.keys():\n",
    "                # print(id)\n",
    "        #get the sub shape\n",
    "        sub_shape = lfdb.filter(ee.Filter.eq(\"ID\", i))\n",
    "\n",
    "        #get all other fire ids that are not this one\n",
    "        not_fires = lfdb.filter(ee.Filter.neq(\"ID\", i))\n",
    "\n",
    "        #get the year and date\n",
    "        this_year = ee.Number(sub_shape.aggregate_array('Year').get(0))\n",
    "        \n",
    "        # print(sub_shape.aggregate_array('Year').get(0).getInfo())\n",
    "        \n",
    "        # if sub_shape.aggregate_array('Year').get(0).getInfo() > 2018:\n",
    "            \n",
    "            \n",
    "\n",
    "        #date ranges for pre and post\n",
    "        pre_start = ee.Date.fromYMD(this_year.subtract(1), 6, 1)\n",
    "        pre_end = ee.Date.fromYMD(this_year.subtract(1), 8, 31)\n",
    "        post_start = pre_start.advance(2, 'year')\n",
    "        post_end = pre_end.advance(2, 'year')\n",
    "\n",
    "\n",
    "        #get the centroid of the polygon\n",
    "        final_buffer = sub_shape.geometry().bounds()\n",
    "\n",
    "        #get area of bounding box, in square kilometers\n",
    "        poly_area = final_buffer.area(maxError = 1, proj ='EPSG:3413').divide(1000 * 1000)\n",
    "\n",
    "        #offset the final_buffer by a random direction of 0.2 degrees\n",
    "        all_rands = [0.00, 0.02, -0.02]\n",
    "\n",
    "        rand1 = random.sample(all_rands, 1)[0]\n",
    "        rand2 = random.sample(all_rands, 1)[0]\n",
    "\n",
    "        #offset\n",
    "        proj = ee.Projection(\"EPSG:4326\").translate(rand1, rand2)\n",
    "\n",
    "        final_buffer = ee.Geometry.Polygon(final_buffer.coordinates(), proj).transform(proj)\n",
    "        final_buffer2 = final_buffer.buffer(distance= 2000).bounds()\n",
    "\n",
    "        final_buffer = final_buffer.buffer(distance= 40000)#.bounds().transform(proj='EPSG:3413', maxError=1)\n",
    "    \n",
    "        #water mask\n",
    "        waterOcc = ee.Image(\"JRC/GSW1_0/GlobalSurfaceWater\").clip(final_buffer).select('occurrence')\n",
    "        jrc_data0 = ee.Image(\"JRC/GSW1_0/Metadata\").select('total_obs').lte(0)\n",
    "        waterOccFilled = waterOcc.unmask(0).max(jrc_data0)\n",
    "        waterMask = waterOccFilled.lt(50);\n",
    "\n",
    "        startYear = pre_start.get('year')\n",
    "\n",
    "        #convert to client side\n",
    "        startYear = startYear.getInfo()  # local string\n",
    "        endYear = str(int(startYear) + 2)\n",
    "        startYear = str(startYear)\n",
    "\n",
    "        #get bounding box\n",
    "        # Map.addLayer(cent)\n",
    "\n",
    "\n",
    "        #------------------------------------------------harmonize landsat\n",
    "        # define years and dates to include in landsat image collection\n",
    "        #  startYear  = '1984'    # what year do you want to start the time series \n",
    "        #  endYear    = '2022'    # what year do you want to end the time series\n",
    "        startDay  = '01-01' # what is the beginning of date filter | month-day\n",
    "        endDay     = '12-30' # what is the end of date filter | month-day\n",
    "\n",
    "        # water_mask = water.filterDate(startYear+'-'+startDay, endYear+'-'+endDay).first().gte(2)\n",
    "\n",
    "\n",
    "        #########################################################################################################\n",
    "        ###### ANNUAL SR TIME SERIES COLLECTION BUILDING FUNCTIONS ##### \n",
    "        #########################################################################################################\n",
    "\n",
    "        #----- MAKE A DUMMY COLLECTOIN FOR FILLTING MISSING YEARS -----\n",
    "        dummyCollection = ee.ImageCollection([ee.Image([0,0,0,0,0,0]).mask(ee.Image(0))]) # make an image collection from an image with 6 bands all set to 0 and then make them masked values\n",
    "\n",
    "\n",
    "        #------ L8 to L7 HARMONIZATION FUNCTION -----\n",
    "        # slope and intercept citation: Roy, D.P., Kovalskyy, V., Zhang, H.K., Vermote, E.F., Yan, L., Kumar, S.S, Egorov, A., 2016, Characterization of Landsat-7 to Landsat-8 reflective wavelength and normalized difference vegetation index continuity, Remote Sensing of Environment, 185, 57-70.(http:#dx.doi.org/10.1016/j.rse.2015.12.024) Table 2 - reduced major axis (RMA) regression coefficients\n",
    "        def harmonizationRoy(oli):\n",
    "            slopes = ee.Image.constant([0.9785, 0.9542, 0.9825, 1.0073, 1.0171, 0.9949])        # create an image of slopes per band for L8 TO L7 regression line - David Roy\n",
    "            itcp = ee.Image.constant([-0.0095, -0.0016, -0.0022, -0.0021, -0.0030, 0.0029])     # create an image of y-intercepts per band for L8 TO L7 regression line - David Roy\n",
    "            y = oli.select(['B2','B3','B4','B5','B6','B7'],['B1', 'B2', 'B3', 'B4', 'B5', 'B7']).resample('bicubic').subtract(itcp.multiply(10000)).divide(slopes).set('system:time_start', oli.get('system:time_start'))                 \n",
    "            return y.toShort()                                                                       \n",
    "\n",
    "\n",
    "        #------ RETRIEVE A SENSOR SR COLLECTION FUNCTION -----\n",
    "        def getSRcollection(start_date, end_date, sensor):\n",
    "            # get a landsat collection for given year, day range, and sensor\n",
    "            srCollection = ee.ImageCollection('LANDSAT/'+ sensor + '/C02/T1_L2').filterDate(start_date, end_date)\n",
    "\n",
    "            return srCollection\n",
    "\n",
    "        #get all collection5\n",
    "        # lt4 = getSRcollection(startYear+'-'+startDay, endYear+'-'+endDay, 'LT04')  \n",
    "        lt5 = getSRcollection(startYear+'-'+startDay, endYear+'-'+endDay, 'LT05').filterBounds(final_buffer)    \n",
    "        le7 = getSRcollection(startYear+'-'+startDay, endYear+'-'+endDay, 'LE07').filterBounds(final_buffer)     \n",
    "        lc8 = getSRcollection(startYear+'-'+startDay, endYear+'-'+endDay, 'LC08').filterBounds(final_buffer)        \n",
    "        sent= sent_2A.filterBounds(final_buffer)\n",
    "\n",
    "        #         #------------------------------------------Landsat 5 corrections\n",
    "\n",
    "        #select bands\n",
    "        pre_lt5 = lt5.filterDate(pre_start, pre_end).map(mask).map(land_scale).filterBounds(final_buffer).select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "\n",
    "        #       #ensure we have imagery for the sensor\n",
    "        if pre_lt5.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "            #take the median\n",
    "            pre_lt5 = pre_lt5.median().clip(final_buffer)\n",
    "\n",
    "            #calculate nbr, ndvi and ndii\n",
    "            pre_lt5_nbr = pre_lt5.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).toFloat()\n",
    "            pre_lt5_ndvi = pre_lt5.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).toFloat()\n",
    "            pre_lt5_ndii = pre_lt5.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).toFloat()\n",
    "\n",
    "            #add the bands back\n",
    "            pre_lt5 = pre_lt5.addBands(pre_lt5_nbr).addBands(pre_lt5_ndvi).addBands(pre_lt5_ndii)\n",
    "\n",
    "            #apply the corrections\n",
    "\n",
    "            l5_pre_corr = pre_lt5.multiply(l5_corr[1]).add(pre_lt5.pow(2).multiply(l5_corr[2])).add(pre_lt5.pow(3).multiply(l5_corr[3])).add(l5_corr[0])\n",
    "\n",
    "        #-------now do post-fire\n",
    "        #select bands\n",
    "        post_lt5 = lt5.filterDate(post_start, post_end).map(mask).map(land_scale).filterBounds(final_buffer).select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "\n",
    "        #       #ensure we have imagery for the sensor\n",
    "        if post_lt5.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "\n",
    "            #take the median\n",
    "            post_lt5 = post_lt5.median().clip(final_buffer)\n",
    "\n",
    "            #calculate nbr, ndvi and ndii\n",
    "            post_lt5_nbr = post_lt5.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).toFloat()\n",
    "            post_lt5_ndvi = post_lt5.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).toFloat()\n",
    "            post_lt5_ndii = post_lt5.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).toFloat()\n",
    "\n",
    "            #add the bands back\n",
    "            post_lt5 = post_lt5.addBands(post_lt5_nbr).addBands(post_lt5_ndvi).addBands(post_lt5_ndii)\n",
    "\n",
    "            #apply the corrections\n",
    "\n",
    "            l5_post_corr = post_lt5.multiply(l5_corr[1]).add(post_lt5.pow(2).multiply(l5_corr[2])).add(post_lt5.pow(3).multiply(l5_corr[3])).add(l5_corr[0])\n",
    "\n",
    "\n",
    "            #         #------------------------------------------Landsat 7, no corrections but get things clipped and do pre fire/post_fire stuff\n",
    "\n",
    "\n",
    "        #select bands\n",
    "        pre_le7 = le7.filterDate(pre_start, pre_end).map(mask).map(land_scale).filterBounds(final_buffer).select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "\n",
    "              #ensure we have imagery for the sensor\n",
    "        if pre_le7.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "\n",
    "            #take the median\n",
    "            pre_le7 = pre_le7.median().clip(final_buffer)\n",
    "\n",
    "            #calculate nbr, ndvi and ndii\n",
    "            pre_le7_nbr = pre_le7.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).toFloat()\n",
    "            pre_le7_ndvi = pre_le7.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).toFloat()\n",
    "            pre_le7_ndii = pre_le7.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).toFloat()\n",
    "\n",
    "            #add the bands back\n",
    "            pre_le72 = pre_le7.addBands(pre_le7_nbr).addBands(pre_le7_ndvi).addBands(pre_le7_ndii)\n",
    "\n",
    "#         #-------now do post-fire\n",
    "#         #select bands\n",
    "        post_le7 = le7.filterDate(post_start, post_end).map(mask).map(land_scale).filterBounds(final_buffer).select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "\n",
    "        #       #ensure we have imagery for the sensor\n",
    "        if post_le7.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "            #take the median\n",
    "            post_le7 = post_le7.median().clip(final_buffer)\n",
    "\n",
    "            #calculate nbr, ndvi and ndii\n",
    "            post_le7_nbr = post_le7.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).toFloat()\n",
    "            post_le7_ndvi = post_le7.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).toFloat()\n",
    "            post_le7_ndii = post_le7.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).toFloat()\n",
    "\n",
    "            #add the bands back\n",
    "            post_le72 = post_le7.addBands(post_le7_nbr).addBands(post_le7_ndvi).addBands(post_le7_ndii)\n",
    "\n",
    "        #------------------------------------------Landsat 8 corrections\n",
    "\n",
    "\n",
    "        #-------first do pre-fire\n",
    "\n",
    "        #select bands\n",
    "        pre_lc8 = lc8.filterDate(pre_start, pre_end).map(mask).map(land_scale).filterBounds(final_buffer).select(['SR_B2','SR_B3','SR_B4','SR_B5','SR_B6','SR_B7'],['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "\n",
    "        #       #ensure we have imagery for the sensor\n",
    "        if pre_lc8.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "\n",
    "            #take the median\n",
    "            pre_lc8 = pre_lc8.median().clip(final_buffer)\n",
    "\n",
    "            #calculate nbr, ndvi and ndii\n",
    "            pre_lc8_nbr = pre_lc8.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).toFloat()\n",
    "            pre_lc8_ndvi = pre_lc8.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).toFloat()\n",
    "            pre_lc8_ndii = pre_lc8.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).toFloat()\n",
    "\n",
    "            #add the bands back\n",
    "            pre_lc8 = pre_lc8.addBands(pre_lc8_nbr).addBands(pre_lc8_ndvi).addBands(pre_lc8_ndii)\n",
    "\n",
    "            #apply the corrections\n",
    "\n",
    "            l8_pre_corr = pre_lc8.multiply(l8_corr[1]).add(pre_lc8.pow(2).multiply(l8_corr[2])).add(pre_lc8.pow(3).multiply(l8_corr[3])).add(l8_corr[0])\n",
    "\n",
    "        #-------now do post-fire\n",
    "          #select bands\n",
    "        post_lc8 = lc8.filterDate(post_start, post_end).map(mask).map(land_scale).filterBounds(final_buffer).select(['SR_B2','SR_B3','SR_B4','SR_B5','SR_B6','SR_B7'],['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "\n",
    "        #       #ensure we have imagery for the sensor\n",
    "        if post_lc8.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "\n",
    "        #take the median\n",
    "            post_lc8 = post_lc8.median().clip(final_buffer)\n",
    "\n",
    "            #calculate nbr, ndvi and ndii\n",
    "            post_lc8_nbr = post_lc8.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).toFloat()\n",
    "            post_lc8_ndvi = post_lc8.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).toFloat()\n",
    "            post_lc8_ndii = post_lc8.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).toFloat()\n",
    "\n",
    "            #add the bands back\n",
    "            post_lc8 = post_lc8.addBands(post_lc8_nbr).addBands(post_lc8_ndvi).addBands(post_lc8_ndii)\n",
    "\n",
    "            #apply the corrections\n",
    "\n",
    "            l8_post_corr = post_lc8.multiply(l8_corr[1]).add(post_lc8.pow(2).multiply(l8_corr[2])).add(post_lc8.pow(3).multiply(l8_corr[3])).add(l8_corr[0])\n",
    "            # #          #------------------------------------------Sentinel 2 corrections, use landsat 8 coefficients\n",
    "\n",
    "\n",
    "        #-------first do pre-fire\n",
    "\n",
    "        # select bands\n",
    "        pre_sent = sent_2A.filterDate(pre_start, pre_end).map(sent_scale).filterBounds(final_buffer).select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "\n",
    "        #       #ensure we have imagery for the sensor\n",
    "        if pre_sent.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "\n",
    "                #take the median\n",
    "            pre_sent = pre_sent.median().clip(final_buffer)\n",
    "\n",
    "            #calculate nbr, ndvi and ndii\n",
    "            pre_sent_nbr = pre_sent.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).toFloat()\n",
    "            pre_sent_ndvi = pre_sent.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).toFloat()\n",
    "            pre_sent_ndii = pre_sent.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).toFloat()\n",
    "\n",
    "            #add the bands back\n",
    "            pre_sent = pre_sent.addBands(pre_sent_nbr).addBands(pre_sent_ndvi).addBands(pre_sent_ndii)\n",
    "\n",
    "            #apply the corrections\n",
    "\n",
    "            sent_pre_corr = pre_sent.multiply(l8_corr[1]).add(pre_sent.pow(2).multiply(l8_corr[2])).add(pre_sent.pow(3).multiply(l8_corr[3])).add(l8_corr[0])\n",
    "\n",
    "        #-------now do post-fire\n",
    "        #select bands\n",
    "        post_sent = sent_2A.filterDate(post_start, post_end).map(sent_scale).filterBounds(final_buffer).select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).map(to_float)\n",
    "\n",
    "        #       #ensure we have imagery for the sensor\n",
    "        if post_sent.size().getInfo() > 0 :\n",
    "\n",
    "\n",
    "\n",
    "            #take the median\n",
    "            post_sent = post_sent.median().clip(final_buffer)\n",
    "\n",
    "            #calculate nbr, ndvi and ndii\n",
    "            post_sent_nbr = post_sent.normalizedDifference(['SR_B4', 'SR_B7']).select([0], ['NBR']).toFloat()\n",
    "            post_sent_ndvi = post_sent.normalizedDifference(['SR_B4', 'SR_B3']).select([0], ['NDVI']).toFloat()\n",
    "            post_sent_ndii = post_sent.normalizedDifference(['SR_B4', 'SR_B5']).select([0], ['NDII']).toFloat()\n",
    "\n",
    "            #add the bands back\n",
    "            post_sent = post_sent.addBands(post_sent_nbr).addBands(post_sent_ndvi).addBands(post_sent_ndii)\n",
    "\n",
    "            #apply the corrections\n",
    "\n",
    "            sent_post_corr = post_sent.multiply(l8_corr[1]).add(post_sent.pow(2).multiply(l8_corr[2])).add(post_sent.pow(3).multiply(l8_corr[3])).add(l8_corr[0])\n",
    "\n",
    "\n",
    "        #try to see if image exists, if so append\n",
    "\n",
    "        #----------------------all prefire\n",
    "\n",
    "        #       #empty list for pre-fire, use this to combine if we have land 5, 7, 8 or sentinel \n",
    "        pre_input = []\n",
    "\n",
    "        try:\n",
    "            l5_pre_corr.getInfo()\n",
    "            pre_input.append(l5_pre_corr)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            pre_le72.getInfo()\n",
    "            pre_input.append(pre_le72)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            l8_pre_corr.getInfo()\n",
    "            pre_input.append(l8_pre_corr)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            sent_pre_corr.getInfo()\n",
    "            pre_input.append(sent_pre_corr)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #----------------------all postfire\n",
    "\n",
    "        #         #       #empty list for post-fire, use this to combine if we have land 5, 7, 8 or sentinel \n",
    "        post_input = []\n",
    "\n",
    "        try:\n",
    "            l5_post_corr.getInfo()\n",
    "            post_input.append(l5_post_corr)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            post_le72.getInfo()\n",
    "            post_input.append(post_le72)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            l8_post_corr.getInfo()\n",
    "            post_input.append(l8_post_corr)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            sent_post_corr.getInfo()\n",
    "            post_input.append(sent_post_corr)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        \n",
    "\n",
    "        if (len(pre_input) >0) and (len(post_input) > 0):\n",
    "\n",
    "            #take the median of the image collections\n",
    "            pre_input = ee.ImageCollection(pre_input)\n",
    "            post_input = ee.ImageCollection(post_input)\n",
    "\n",
    "\n",
    "\n",
    "          #try and except,, if we have data in both pre and post get the dnbr, otherwise pass\n",
    "\n",
    "            # try:\n",
    "            #     if (pre_input.size().getInfo() > 0) and (post_input.size().getInfo() > 0):\n",
    "\n",
    "            pre_input = pre_input.median()\n",
    "            post_input= post_input.median()\n",
    "\n",
    "            #difference the bands\n",
    "            raw_bands = pre_input.subtract(post_input).multiply(1000)\n",
    "\n",
    "\n",
    "            #we need to see which image ids from the entire lfdb are already included in the buffer\n",
    "            lfdb_filtered_orig = lfdb.filterBounds(final_buffer)\n",
    "\n",
    "            #ensure all fires are within the actual year of interest (this_year) and two years prior, otherwise ignore\n",
    "\n",
    "            first_year =  int(startYear) + 1\n",
    "            second_year =  int(startYear)\n",
    "            third_year =  int(startYear) - 1\n",
    "            fourth_year = int(startYear) + 2\n",
    "\n",
    "            lfdb_filtered = lfdb_filtered_orig.filter(ee.Filter.eq(\"Year\", first_year))\n",
    "\n",
    "            bad_filtered = lfdb_filtered_orig.filter(ee.Filter.Or(ee.Filter.eq(\"Year\", second_year), ee.Filter.eq(\"Year\", third_year), ee.Filter.eq(\"Year\", fourth_year)))\n",
    "\n",
    "\n",
    "            #get ids which are in image\n",
    "            all_dates_new = ee.List(lfdb_filtered.distinct([\"ID\"]).aggregate_array(\"ID\")).getInfo()\n",
    "\n",
    "\n",
    "            #remove ids from all dates which we do not need anymore\n",
    "            all_dates = [i for i in all_dates if i not in all_dates_new]\n",
    "\n",
    "\n",
    "            #now where the fire is turn the values to 0 and where the fire isn't turn them to 0\n",
    "            # fire_rast = sub_shape.filter(ee.Filter.notNull(['ID'])).reduceToImage(properties = ['ID'], reducer =  ee.Reducer.first())\n",
    "\n",
    "            fire_rast = lfdb_filtered.reduceToImage(properties= ['ID'], reducer = ee.Reducer.first())\n",
    "\n",
    "            #bad fire rast\n",
    "            bad_fire_rast = bad_filtered.reduceToImage(properties= ['ID'], reducer = ee.Reducer.first())\n",
    "\n",
    "            #change values\n",
    "            fire_rast = fire_rast.where(fire_rast.gt(0), 1)\n",
    "\n",
    "            #chabnge values for bad fire raster \n",
    "            bad_fire_rast = bad_fire_rast.where(bad_fire_rast.gt(0), 1)\n",
    "\n",
    "            #if the fires overlap we want to keep those locations\n",
    "            bad_fire_rast = bad_fire_rast.where(bad_fire_rast.eq(1).And(fire_rast.eq(1)), 2).unmask(-999)\n",
    "\n",
    "            # #fire_locaation values to 1 by first copying ndvi\n",
    "            fire_rast = fire_rast.rename(['y'])\n",
    "\n",
    "            #copy the first values of raw_bands\n",
    "            y = post_input.select(['SR_B2'], ['y'])#.toShort()\n",
    "\n",
    "            #turn all values of y to 0\n",
    "            y  = y.where(y.gt(0), 0)\n",
    "\n",
    "            #turn values to 1 where fire_rast is 1\n",
    "            y  = y.where(fire_rast.eq(1), 1)\n",
    "\n",
    "            b1 = raw_bands.select('SR_B1').cast({'SR_B1':'short'}) #0\n",
    "            b2 = raw_bands.select('SR_B2').cast({'SR_B2':'short'}) #1\n",
    "            b3 = raw_bands.select('SR_B3').cast({'SR_B3':'short'}) #2\n",
    "            b4 = raw_bands.select('SR_B4').cast({'SR_B4':'short'}) #3\n",
    "            b5 = raw_bands.select('SR_B5').cast({'SR_B5':'short'}) #4\n",
    "            b6 = raw_bands.select('SR_B7').cast({'SR_B7':'short'}) #5\n",
    "            b7 = raw_bands.select('NBR').cast({'NBR':'short'}) #band 6 is dnbr is numpy\n",
    "            b8 = raw_bands.select('NDVI').cast({'NDVI':'short'}) #7\n",
    "            b9 = raw_bands.select('NDII').cast({'NDII':'short'}) #8\n",
    "            # b10 = raw_bands.select('y').cast({'y':'float'})\n",
    "            b10 = y.select('y').cast({'y':'short'})\n",
    "\n",
    "            raw_bands = b1.addBands(b2).addBands(b3).addBands(b4).addBands(b5).addBands(b6).addBands(b7).addBands(b8).addBands(b9)\n",
    "            # raw_bands = raw_bands.updateMask(waterOccFilled.lt(50).And(bad_fire_rast.neq(1)))\n",
    "            raw_bands = raw_bands.updateMask(bad_fire_rast.neq(1))\n",
    "\n",
    "            raw_bands = raw_bands.addBands(b10)\n",
    "\n",
    "\n",
    "\n",
    "        #loop through and ensure that the description is not \n",
    "            print(f\"Downloading {fname}\")\n",
    "            \n",
    "\n",
    "\n",
    "            task = ee.batch.Export.image.toCloudStorage(\n",
    "                                    image = raw_bands.toShort(),\n",
    "                                    region=final_buffer2, \n",
    "                                    description='median_' + str(i),\n",
    "                                    scale=30,\n",
    "                                    crs='EPSG:3413',\n",
    "                                    # crs='EPSG:4326',\n",
    "\n",
    "                                    maxPixels=1e13,\n",
    "                                    bucket = 'smp-scratch')\n",
    "\n",
    "            task.start()\n",
    "\n",
    "\n",
    "\n",
    "    # except:\n",
    "    #     pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6bd4f7-47e6-4d24-9cd7-7b5c909fbc5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e6b39-8ee3-4be9-bcbb-f80c202e60b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-gee_ml]",
   "language": "python",
   "name": "conda-env-.conda-gee_ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
