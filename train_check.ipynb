{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3345cfd-3fb0-4f05-aa4c-298bdccef3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spotter5/.local/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       6\n",
      "0   21.0\n",
      "1  974.0\n",
      "Number of devices: 4\n",
      "----------\n",
      "deep_supervision = True\n",
      "names of output tensors are listed as follows (\"sup0\" is the shallowest supervision layer;\n",
      "\"final\" is the final output layer):\n",
      "\n",
      "\tunet_output_sup0_activation\n",
      "\tunet_output_sup1_activation\n",
      "\tunet_output_final_activation\n"
     ]
    }
   ],
   "source": [
    "# !/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Read in packages\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
    "import os\n",
    "import segmentation_models as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import concatenate, Conv2DTranspose, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, Input, AvgPool2D\n",
    "from tensorflow.keras.models import Model\n",
    "from keras_unet_collection import models\n",
    "import tensorflow_addons as tfa\n",
    "import logging\n",
    "\n",
    "\n",
    "#function to standardize\n",
    "# def normalize_meanstd(a, axis=None): \n",
    "# \t# axis param denotes axes along which mean & std reductions are to be performed\n",
    "# \tmean = np.mean(a, axis=axis, keepdims=True)\n",
    "# \tstd = np.sqrt(((a - mean)**2).mean(axis=axis, keepdims=True))\n",
    "# \treturn (a - mean) / std\n",
    "\n",
    "# #function to normalize\n",
    "# def normalize(a, axis=None): \n",
    "#     # axis param denotes axes along which mean & std reductions are to be performed\n",
    "#     minv = np.nanmin(a, axis=axis, keepdims=True)\n",
    "#     maxv = np.nanmax(a, axis=axis, keepdims=True)\n",
    "#     return (a - minv) / (maxv - minv)\n",
    "\n",
    "\n",
    "#apply standardization\n",
    "# img = normalize(img, axis=(0,1))\n",
    "\n",
    "# from tensorflow import tensorflow.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "\n",
    "# Using logging since if the jupyter noteboock disconnects I want to keep track\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# logger = logging.getLogger()\n",
    "# fhandler = logging.FileHandler(filename='/att/nobackup/spotter5/cnn_mapping/nbac_training/test_log.log', mode='a')\n",
    "# logger.addHandler(fhandler)\n",
    "# # logging.basicConfig(filename='/att/nobackup/spotter5/cnn_mapping/nbac_training/test_log.log', level=logging.INFO)\n",
    "# logging.warning('This is a warning message')\n",
    "# import sys\n",
    "# old_stdout = sys.stdout\n",
    "\n",
    "# log_file = open(\"/adapt/nobackup/people/spotter5/cnn_mapping/nbac_training/test_log.log\",\"w\")\n",
    "\n",
    "# sys.stdout = log_file\n",
    "\n",
    "# print(\"this will be written to message.log\")\n",
    "\n",
    "# sys.stdout = old_stdout\n",
    "\n",
    "\n",
    "# # In[ ]:\n",
    "\n",
    "\n",
    "# #Initialize GPUS with tensorflow\n",
    "\n",
    "\n",
    "# # In[2]:\n",
    "\n",
    "\n",
    "# gpu_devices = tensorflow.config.experimental.list_physical_devices('GPU')\n",
    "# for device in gpu_devices:\n",
    "#     tensorflow.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "\n",
    "# # Check GPUS are running\n",
    "\n",
    "# # In[3]:\n",
    "\n",
    "\n",
    "# gpu_info = get_ipython().getoutput('nvidia-smi')\n",
    "# gpu_info = '\\n'.join(gpu_info)\n",
    "# if gpu_info.find('failed') >= 0:\n",
    "#   print('Not connected to a GPU')\n",
    "# else:\n",
    "#   print(gpu_info)\n",
    "# # watch -n0.5 nvidia-smi\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# devices = device_lib.list_local_devices()\n",
    "\n",
    "# def sizeof_fmt(num, suffix='B'):\n",
    "#     for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "#         if abs(num) < 1024.0:\n",
    "#             return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "#         num /= 1024.0\n",
    "#     return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "# for d in devices:\n",
    "#     t = d.device_type\n",
    "#     name = d.physical_device_desc\n",
    "#     l = [item.split(':',1) for item in name.split(\", \")]\n",
    "#     name_attr = dict([x for x in l if len(x)==2])\n",
    "#     dev = name_attr.get('name', 'Unnamed device')\n",
    "#     print(f\" {d.name} || {dev} || {t} || {sizeof_fmt(d.memory_limit)}\")\n",
    "\n",
    "\n",
    "# Read in the training files\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "min_max = pd.read_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_global_min_max_cutoff_proj.csv\").reset_index(drop = True)\n",
    "\n",
    "min_max = min_max[['6']]\n",
    "\n",
    "print(min_max)\n",
    "#functin to standardize all bands at once\n",
    "\n",
    "\n",
    "#function to standardize\n",
    "def normalize_meanstd(a, axis=None): \n",
    "    # axis param denotes axes along which mean & std reductions are to be performed\n",
    "    mean = np.mean(a, axis=axis, keepdims=True)\n",
    "    std = np.sqrt(((a - mean)**2).mean(axis=axis, keepdims=True))\n",
    "    return (a - mean) / std\n",
    "\n",
    "#function to normalize\n",
    "def normalize(a, axis=None): \n",
    "    # axis param denotes axes along which mean & std reductions are to be performed\n",
    "    minv = np.min(a, axis=axis, keepdims=True)\n",
    "    maxv = np.max(a, axis=axis, keepdims=True)\n",
    "    return (a - minv) / (maxv - minv)\n",
    "\n",
    "\n",
    "#function to get files from storage bucket\n",
    "def get_files(bucket_path):\n",
    "\n",
    "\t\"\"\"argument is the path to where the numpy\n",
    "\tsave files are located, return a list of filenames\n",
    "\t\"\"\"\n",
    "\tall = []\n",
    "\n",
    "\t#list of files\n",
    "\tfiles = os.listdir(bucket_path)\n",
    "\n",
    "\t#get list of filenames we will use, notte I remove images that don't have a target due to clouds\n",
    "\tfile_names = []\n",
    "\tfor f in files:\n",
    "\n",
    "\t\tif f.endswith('.npy'):\n",
    "\n",
    "\n",
    "\t\t\tall.append(os.path.join(bucket_path, f))\n",
    "\treturn(all)\n",
    "\n",
    "\n",
    "#get all the pathways\n",
    "training_names = pd.read_csv('/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_proj_0_final_128_training_files.csv')['Files'].tolist()[:100]\n",
    "\n",
    "validation_names = pd.read_csv('/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_proj_0_final_128_validation_files.csv')['Files'].tolist()[:100]\n",
    "testing_names = pd.read_csv('/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_proj_0_final_128_testing_files.csv')['Files'].tolist()[:100]\n",
    "\n",
    "# bad = '/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_wgs_subs_0_128/2_1_10603.npy'\n",
    "# training_names = [i for i in training_names if i != bad]\n",
    "# validation_names = [i for i in training_names if i != bad]\n",
    "# testing_names = [i for i in training_names if i != bad]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "\n",
    "#function to normalize within range\n",
    "def normalize(start, end, arr):\n",
    "    width = end - start\n",
    "    res = (arr - np.nanmin(arr))/(np.nanmax(arr)- np.nanmin(arr)) * width + start\n",
    "\n",
    "#     res = (arr - arr.min())/(arr.max() - arr.min()) * width + start\n",
    "    return res\n",
    "\n",
    "class img_gen(tensorflow.keras.utils.Sequence):\n",
    "\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\n",
    "    Inputs are batch size, the image size, the input paths (x) and target paths (y)\n",
    "    \"\"\"\n",
    "\n",
    "    #will need pre defined variables batch_size, img_size, input_img_paths and target_img_paths\n",
    "    def __init__(self, batch_size, img_size, input_img_paths):\n",
    "\t    self.batch_size = batch_size\n",
    "\t    self.img_size = img_size\n",
    "\t    self.input_img_paths = input_img_paths\n",
    "\t    self.target_img_paths = input_img_paths\n",
    "\n",
    "    #number of batches the generator is supposed to produceis the length of the paths divided by the batch siize\n",
    "    def __len__(self):\n",
    "\t    return len(self.input_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_img_paths = self.input_img_paths[i : i + self.batch_size] #for a given index get the input batch pathways (x)\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size] #for a given index get the input batch pathways (y)\n",
    "\t\t\n",
    "        x = np.zeros((self.batch_size,) + self.img_size, dtype=\"float32\") #create matrix of zeros which will have the dimension (batch_size, height, wideth, n_bands), 8 is the n_bands\n",
    "        \n",
    "  \n",
    "        #start populating x by enumerating over the input img paths\n",
    "        for j, path in enumerate(batch_img_paths):\n",
    "\n",
    "            #load image\n",
    "            img =  np.round(np.load(path), 3)[:, :, 6]\n",
    "\n",
    "            # img = img * 1000\n",
    "            img = img.astype(float)\n",
    "            img = np.round(img, 3)\n",
    "            img[img == 0] = -999\n",
    "\n",
    "            img[np.isnan(img)] = -999\n",
    "\n",
    "\n",
    "            img[img == -999] = np.nan\n",
    "\n",
    "            in_shape = img.shape\n",
    "\n",
    "            #turn to dataframe to normalize\n",
    "            img = img.reshape(img.shape[0] * img.shape[1])\n",
    "\n",
    "            img = pd.DataFrame(img)\n",
    "\n",
    "            img.columns = min_max.columns\n",
    "\n",
    "            img = pd.concat([min_max, img]).reset_index(drop = True)\n",
    "\n",
    "\n",
    "            #normalize 0 to 1\n",
    "            img = pd.DataFrame(scaler.fit_transform(img))\n",
    "\n",
    "            img = img.iloc[2:]\n",
    "#\n",
    "#             img = img.values.reshape(in_shape)\n",
    "            img = img.values.reshape(in_shape)\n",
    "\n",
    "#             replace nan with -1\n",
    "            img[np.isnan(img)] = -1\n",
    "\n",
    "#apply standardization\n",
    "# img = normalize(img, axis=(0,1))\n",
    "\n",
    "            img = np.round(img, 3)\n",
    "            #populate x\n",
    "            x[j] = img#[:, :, 4:] index number is not included, \n",
    "\n",
    "\n",
    "        #do tthe same thing for y\n",
    "        y = np.zeros((self.batch_size,) + self.img_size, dtype=\"uint8\")\n",
    "\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "\n",
    "            #load image\n",
    "            img =  np.round(np.load(path), 3)[:, :, -1]\n",
    "\n",
    "            img = img.astype(int)\n",
    "\n",
    "            img[img < 0] = 0\n",
    "            img[img >1] = 0\n",
    "            img[~np.isin(img, [0,1])] = 0\n",
    "\n",
    "            img[np.isnan(img)] = 0\n",
    "            img = img.astype(int)\n",
    "\n",
    "            # img =  tf.keras.utils.to_categorical(img, num_classes = 2)\n",
    "            # y[j] = np.expand_dims(img, 2) \n",
    "            y[j] = img\n",
    "  \n",
    "       \n",
    "    #Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:\n",
    "    # y[j] -= 1\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# Read in the images based on the generator\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "#batch size and img size\n",
    "BATCH_SIZE = 15\n",
    "GPUS = [\"GPU:0\", \"GPU:1\", \"GPU:2\", \"GPU:3\"]\n",
    "strategy = tensorflow.distribute.MirroredStrategy() #can add GPUS here to select specific ones\n",
    "print('Number of devices: %d' % strategy.num_replicas_in_sync) \n",
    "\n",
    "batch_size = BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "\n",
    "\n",
    "\n",
    "#image size\n",
    "img_size = (128, 128)\n",
    "# img_size = (128, 128)\n",
    "\n",
    "#number of classes to predict\n",
    "num_classes = 1\n",
    "\n",
    "#get images\n",
    "train_gen = img_gen(batch_size, img_size, training_names)\n",
    "val_gen = img_gen(batch_size, img_size, validation_names)\n",
    "test_gen = img_gen(batch_size, img_size, testing_names)\n",
    "#\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "tensorflow.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "optimizer = tensorflow.keras.optimizers.Adam() #this is 1e-3, default or 'rmsprop'\n",
    "LR = 0.0005\n",
    "    \n",
    "loss= tensorflow.keras.losses.BinaryFocalCrossentropy(\n",
    "    from_logits=False,\n",
    "    gamma = 2.0,\n",
    "    alpha = 0.25)\n",
    "\n",
    "# f.keras.losses.BinaryFocalCrossentropy(gamma=2.0, alpha=0.25)\n",
    "# loss = tensorflow.keras.losses.BinaryFocalCrossentropy(\n",
    "#     apply_class_balancing=False,\n",
    "#     alpha=0.25,\n",
    "#     gamma=2.0,\n",
    "#     from_logits=False,\n",
    "#     label_smoothing=0.0,\n",
    "#     axis=-1,\n",
    "#     reduction=losses_utils.ReductionV2.AUTO,\n",
    "#     name='binary_focal_crossentropy'\n",
    "# )\n",
    "\n",
    "\n",
    "callbacks = [tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/models/l8_collection2_dnbr_one_128_2d_ds_proj_final.tf\",\n",
    "#     verbose=1,\n",
    "    save_weights_only=False,\n",
    "    save_best_only=True,\n",
    "    monitor='val_mean_iou',\n",
    "    mode = 'max'),\n",
    "    tensorflow.keras.callbacks.EarlyStopping(monitor='loss', patience=10)]\n",
    "    \n",
    "tensorflow.keras.callbacks.ReduceLROnPlateau(monitor = 'loss', mode = 'min', patience = 10, min_delta=0.001, min_LR = LR/25, verbose = 1)\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    \n",
    "    #one [16,32,64,128]\n",
    "    #two [16,32,64,128,256]\n",
    "    #three [32,64,128,256]\n",
    "    #four [32,64,128,256,512]\n",
    "    #five [16,32,64,128,256,512,1024]\n",
    "\n",
    "\n",
    "    model_unet_from_scratch = models.unet_plus_2d((None, None, 1), filter_num= [16,32,64,128], #make smaller64, 128, 256, 512,[16, 32, 64, 128]\n",
    "                       n_labels=num_classes, \n",
    "                       stack_num_down=2, stack_num_up=2, \n",
    "                       activation='ReLU', \n",
    "                       output_activation='Sigmoid', \n",
    "                       batch_norm=True, pool=False, unpool=False, \n",
    "                       backbone='EfficientNetB7', weights=None, \n",
    "                       freeze_backbone=False, freeze_batch_norm=False, \n",
    "                       deep_supervision = True,\n",
    "                       name='unet')\n",
    "\n",
    "    # model_unet_from_scratch = models.unet_3plus_2d((None, None, 1), n_labels=num_classes, filter_num_down=[16,32,64,128], \n",
    "    #                          filter_num_skip='auto', filter_num_aggregate='auto', \n",
    "    #                         backbone='EfficientNetB7', weights=None, \n",
    "    #                          freeze_backbone=False,\n",
    "    #                          stack_num_down=2, stack_num_up=1, activation='ReLU', output_activation='Sigmoid',\n",
    "    #                          batch_norm=True, pool='max', unpool=False, deep_supervision=True, name='unet')\n",
    "\t\n",
    "#     model.set_weights(listOfNumpyArrays)\n",
    "    model_unet_from_scratch.compile(loss='binary_crossentropy',\n",
    "                                    # loss = loss,\n",
    "                                    optimizer='adam',\n",
    "                                    metrics=[sm.metrics.Precision(threshold=0.5),\n",
    "                                      sm.metrics.Recall(threshold=0.5),\n",
    "                                      sm.metrics.FScore(threshold=0.5), \n",
    "                                      sm.metrics.IOUScore(threshold=0.5),\n",
    "                                      'accuracy'])\n",
    "\n",
    "#fit the model\n",
    "history = model_unet_from_scratch.fit(\n",
    "    train_gen,\n",
    "    epochs=2,\n",
    "    callbacks = callbacks,\n",
    "    validation_data=val_gen,\n",
    "    verbose = 0) \n",
    "\n",
    "# model_unet_from_scratch.save(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_sent_collection2_079_128.h5\")\n",
    "# model_unet_from_scratch.save(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/models/l8_collection2_dnbr_one_128_2d_ds_proj_final.tf\")\n",
    "\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "#save output\n",
    "# result = pd.DataFrame({'Precision': history_dict[\"precision\"],\n",
    "#                        'Val_Precision': history_dict['val_precision'],\n",
    "#                        'Recall': history_dict[\"recall\"],\n",
    "#                        'Val_Recall': history_dict['recall'],\n",
    "#                        'F1': history_dict[\"f1-score\"],\n",
    "#                        'Val_F1': history_dict['val_f1-score'],\n",
    "#                        'IOU': history_dict[\"iou_score\"],\n",
    "#                        'Val_IOU': history_dict['val_iou_score'],\n",
    "#                        'Loss': history_dict['loss'],\n",
    "#                        'Val_Loss': history_dict['val_loss']})\n",
    "\n",
    "result = pd.DataFrame({'Precision': history_dict[\"unet_output_final_activation_precision\"],\n",
    "                       'Val_Precision': history_dict['val_unet_output_final_activation_precision'],\n",
    "                       'Recall': history_dict[\"unet_output_final_activation_recall\"],\n",
    "                       'Val_Recall': history_dict['val_unet_output_final_activation_recall'],\n",
    "                       'F1': history_dict[\"unet_output_final_activation_f1-score\"],\n",
    "                       'Val_F1': history_dict['val_unet_output_final_activation_f1-score'],\n",
    "                       'IOU': history_dict[\"unet_output_final_activation_iou_score\"],\n",
    "                       'Val_IOU': history_dict['val_unet_output_final_activation_iou_score'],\n",
    "                       'Loss': history_dict['unet_output_final_activation_loss'],\n",
    "                       'Val_Loss': history_dict['val_unet_output_final_activation_loss'],\n",
    "                      'Accuracy': history_dict['unet_output_final_activation_accuracy'],\n",
    "                       'Val_Accuracy': history_dict['val_unet_output_final_activation_accuracy']})\n",
    "\n",
    "# result.to_csv(\"/explore/nobackup/people/spotter5/cnn_mapping/nbac_training/l8_collection2_dnbr_one_128_2d_ds_proj_final.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105e6d1a-79b4-4095-ac14-753b48808112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.4982728958129883, 2.2545766830444336],\n",
       " 'unet_output_sup0_activation_loss': [0.7054672837257385, 0.6578888297080994],\n",
       " 'unet_output_sup1_activation_loss': [0.9004752039909363, 0.7905135750770569],\n",
       " 'unet_output_final_activation_loss': [0.892330527305603, 0.8061743378639221],\n",
       " 'unet_output_sup0_activation_precision': [0.07202577590942383,\n",
       "  0.08011670410633087],\n",
       " 'unet_output_sup0_activation_recall': [0.5180217623710632,\n",
       "  0.45478755235671997],\n",
       " 'unet_output_sup0_activation_f1-score': [0.12305566668510437,\n",
       "  0.1313905417919159],\n",
       " 'unet_output_sup0_activation_iou_score': [0.06662964820861816,\n",
       "  0.07120689749717712],\n",
       " 'unet_output_sup0_activation_accuracy': [0.5012593865394592,\n",
       "  0.6101602911949158],\n",
       " 'unet_output_sup1_activation_precision': [0.07153668999671936,\n",
       "  0.07148032635450363],\n",
       " 'unet_output_sup1_activation_recall': [0.7474879026412964,\n",
       "  0.7250954508781433],\n",
       " 'unet_output_sup1_activation_f1-score': [0.12794223427772522,\n",
       "  0.1274741291999817],\n",
       " 'unet_output_sup1_activation_iou_score': [0.06951482594013214,\n",
       "  0.06921007484197617],\n",
       " 'unet_output_sup1_activation_accuracy': [0.3102559447288513,\n",
       "  0.32777100801467896],\n",
       " 'unet_output_final_activation_precision': [0.07165314257144928,\n",
       "  0.07335643470287323],\n",
       " 'unet_output_final_activation_recall': [0.8358404636383057,\n",
       "  0.8690143823623657],\n",
       " 'unet_output_final_activation_f1-score': [0.12963920831680298,\n",
       "  0.1330033838748932],\n",
       " 'unet_output_final_activation_iou_score': [0.070635125041008,\n",
       "  0.07255306839942932],\n",
       " 'unet_output_final_activation_accuracy': [0.23385213315486908,\n",
       "  0.22699381411075592],\n",
       " 'val_loss': [2.076032876968384, 2.0719683170318604],\n",
       " 'val_unet_output_sup0_activation_loss': [0.6911144256591797,\n",
       "  0.6889516711235046],\n",
       " 'val_unet_output_sup1_activation_loss': [0.6913712620735168,\n",
       "  0.6894603371620178],\n",
       " 'val_unet_output_final_activation_loss': [0.6935470700263977,\n",
       "  0.6935563683509827],\n",
       " 'val_unet_output_sup0_activation_precision': [1.0, 1.0],\n",
       " 'val_unet_output_sup0_activation_recall': [3.940986981199046e-10,\n",
       "  3.940986981199046e-10],\n",
       " 'val_unet_output_sup0_activation_f1-score': [3.940986981199046e-10,\n",
       "  3.940986981199046e-10],\n",
       " 'val_unet_output_sup0_activation_iou_score': [3.940986981199046e-10,\n",
       "  3.940986981199046e-10],\n",
       " 'val_unet_output_sup0_activation_accuracy': [0.8919840455055237,\n",
       "  0.8919840455055237],\n",
       " 'val_unet_output_sup1_activation_precision': [1.0, 1.0],\n",
       " 'val_unet_output_sup1_activation_recall': [3.940986981199046e-10,\n",
       "  3.940986981199046e-10],\n",
       " 'val_unet_output_sup1_activation_f1-score': [3.940986981199046e-10,\n",
       "  3.940986981199046e-10],\n",
       " 'val_unet_output_sup1_activation_iou_score': [3.940986981199046e-10,\n",
       "  3.940986981199046e-10],\n",
       " 'val_unet_output_sup1_activation_accuracy': [0.8919840455055237,\n",
       "  0.8919840455055237],\n",
       " 'val_unet_output_final_activation_precision': [0.10793299973011017,\n",
       "  0.1081269308924675],\n",
       " 'val_unet_output_final_activation_recall': [0.9811386466026306,\n",
       "  0.8004623055458069],\n",
       " 'val_unet_output_final_activation_f1-score': [0.19367647171020508,\n",
       "  0.17806905508041382],\n",
       " 'val_unet_output_final_activation_iou_score': [0.10767342895269394,\n",
       "  0.09795335680246353],\n",
       " 'val_unet_output_final_activation_accuracy': [0.12211710959672928,\n",
       "  0.25431111454963684]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56318d-65d2-41de-8456-c49df459cd19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deeplearning3]",
   "language": "python",
   "name": "conda-env-.conda-deeplearning3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
